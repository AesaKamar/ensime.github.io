#+TITLE: Graphpocalypse: indexing in ENSIME
#+AUTHOR: Sam Halliday
#+DATE: Scala Sphere 2017

#+TODO: TODO | RESEARCH | NOTES | CHART | DIAGRAM | DRAWING | CODE | VIDEO

* Introduction
** Sam Halliday =@fommil=

- Chartered Mathematician
  - DSP, optimisation, quantum, machine learning, etc
- Libre Education and Software
  - 5mil textbooks in South Africa (Siyavula)
  - FSF Fellow (they fight for BSD / Apache too!)
  - =netlib-java= (underpinning Spark ML)
  - ENSIME core developer

#+BEGIN_NOTES
I am really an applied mathematician by training, this software thing is really just a hobby that pays the bills.

Before the crash, I did industrial research in digital signal processing, multi-high-dimensional optimisation, quantum mechanics, machine learning and a bunch of other stuff that I could just talk about forever.

I'm really into Free or Libre education and software. When I was a student in Cape Town I was one of the founders of an initiative that eventually became Siyavula and has printed 5 million Free textbooks to students in South Africa.

I'm a fellow of the Free Software Foundation. I believe they do really great things and I'd encourage you to join up even if you don't believe in the GPL. They are doing some great lobbying for all of us against legislation that seeks to undermine our right to use or write Free software, which includes the Apache 2.0 and BSD licenses.

My most used free software project is =netlib-java=, which I spoke about at last year's Scala eXchange. It's included in the Spark Machine Learning library.

But my favourite project is ENSIME, which is an alternative development environment to Eclipse and IntelliJ for Scala and now Java.

#+END_NOTES

** Editor Poll

- IntelliJ
- ScalaIDE
- ENSIME
- Other

** What is ENSIME

- language server for Scala (and Java)
- build tool plugins (sbt, maven, etc)
- text editor plugins (emacs, vim, etc)

** What is an Indexer?

#+BEGIN_SRC ditaa :file images/architecture.png :exports results :cmdline -T
             |
             |                    /--------------------\
             |                    | Indexer            |
             :                    | /----------------\ |
             |                    | |Search Service  | |
             |                    | +----------------+ |
       SWANK / JERKY              | |Source Resolver | |
             |                    | \----------------/ |
             |                    +--------------------/
             |                    |
             |                    | /----------------\
   +------+  :  +--------------+  | |Doc Server      |   +--------+
   |Editor|<--->|   Project    +--+-+----------------+   | JVM{io}|
   +------+  |  +---+----------+    |Debug Manager   +---+--------+
             :      |        ^      +----------------+
             |  +---+----+   |      |Analyzer        +---+-----------+
             |  |File{io}|   |      \----------------/   |scalac     |
             |  |Watchers|   |                           +-----------+
             |  +--------+   |                           |Refactoring|
             |    ^          |                           +-----------+
             |    |          |
             +----|-=--------|-=--------------------------------------
      +--------+  | +--------+-+
      |Files{d}+--+ |.ensime{d}|
      +--------+    +----------+
#+END_SRC

#+RESULTS:
[[file:images/architecture.png]]

#+BEGIN_NOTES
This is an architectural overview of the internals of the
ensime-server, which is bounded here by the dotted lines.

The text editor communicates with the server via SWANK, a
bidirectional TCP/IP sockets protocol using S-Expressions as the
language, or JERKY which is JSON over WebSockets.

The server runs locally, so it also has direct access to the files on
the disc and can watch for changes without needing to be told about
them. This is typically used for detecting changes in the compiled
files rather than looking for changes in source code.

And when the server is started, it needs to be given a =.ensime= file
which defines the project layout. This is typically generated by the
build tool.

Inside the server, everything goes via the central Project class which
effectively just delegates to the relevant sub-component. The two big
parts are the Search Service and the Analyzer:

1. The Search Service indexes all the binaries related to the project,
   including third party jars. We use ASM to do the heavy lifting and
   we persist the results to H2 to enable various types of searches.
   We also build up an index in Lucene for advanced searching, such as
   camel case searching of a classname.
2. The Analyzer is our layer that sits on top of the Scala
   Presentation Compiler, which is an interactive version of the Scala
   Compiler but is supposed to be quicker because it shortcuts various
   stages in order to be responsive. This is the same backend that is
   used by the Scala IDE, but it is released as part of the official
   Scala Compiler jar.
3. We also have the ability to identify source code to binaries, e.g.
   to relate your third party source zip files to the jars that you're
   including. This lets us implement the "jump to source"
   functionality beyond the user's project files.
4. Documentation is hosted via a Spray HTTP server and viewed in a
   normal web browser.
5. A debug manager component allows interactive debugging sessions
   against a running JVM. It manages the state of the threads and
   allows stepping and inspection.

#+END_NOTES

* 1.0
** Index vs Database

- Database
  - retrievable data
  - fully qualified name
- Index
  - human search (CamelCase, simple classname)
  - not needed if you have the FQN

** What we store

#+BEGIN_SRC scala
  final case class FileCheck(
      id: Option[Int],
      filename: String,
      timestamp: Timestamp
  )
#+END_SRC

#+BEGIN_SRC scala
  final case class FqnSymbol(
      id: Option[Int],
      file: String, // the underlying file (class or jar)
      path: String, // URL to the classfile
      fqn: String,  // should really be the primary key
      internal: Option[String], // FQN of a field's type
      source: Option[String], // URL to the source file
      line: Option[Int],
      offset: Option[Int] = None
  )
#+END_SRC

#+BEGIN_NOTES
This is the definition of the very simple SQL schema (we use slick to
access H2).

We have a TABLE to keep track of the timestamp of every file that we
are tracking.

And for every FQN in your project, we store the =file= that it is
contained in, and the URL =path= to that file. There is probably a lot
of wasted memory here because almost everything will have the same
prefix.

The =fqn= should probably be the id field to be honest but we had some
problems with duplicate FQNs in an earlier schema that we've since
resolved (overloaded methods). This is the bytecode FQN plus the
method signature if it's a method.q

The =internal= column is for storing the FQN of a field's type (if
this FQN is a field). With this we can distinguish between fields,
methods and classes.

The =source= is the full URL of the source code for this FQN, along
with the line and offset (if we know it).
#+END_NOTES

** TODO How we extract the data

#+BEGIN_NOTES
- throwing stuff away
- minimal use of scalap
#+END_NOTES

** TODO What we use the data for
** TODO Incremental updates

#+BEGIN_NOTES
perf of fast restarts is a design requirement
#+END_NOTES

** TODO Horror of the code

* 2.0
** TODO Graphpocalypse / GSoC
** TODO What we store now
** TODO Extra source: scalap
** TODO New kinds of queries
** TODO New kinds of features

- find implementations
- find usages
- find dead code
- stats gathering
- linkage / compilation optimisation

** TODO Performance Considerations

- testing

* Future
** TODO more granular API
** TODO perf improvements
** TODO more data sources
** TODO FreeMonad / Swave / Monix / scala-async rewrite
** TODO query language for Lucene index
